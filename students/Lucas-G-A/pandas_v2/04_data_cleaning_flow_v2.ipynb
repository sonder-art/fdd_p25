{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.googleusercontent.com/assets/colab-badge.svg)](https://colab.research.google.com)\n",
        "\n",
        "Si tu repo está en GitHub, usa este enlace editando USER/REPO/BRANCH:\n",
        "[Open in Colab (GitHub)](https://colab.research.google.com/github/USER/REPO/blob/BRANCH/professor/pandas_v2/04_data_cleaning_flow_v2.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 v2 Limpieza de datos end-to-end (versión detallada)\n",
        "\n",
        "Objetivos:\n",
        "- Construir datos \"sucios\" realistas y planificar su limpieza.\n",
        "- Normalizar tipos (texto, numéricos, fechas), tratar nulos y duplicados.\n",
        "- Homologar categorías con catálogos (joins) y validar reglas.\n",
        "- Guardar un dataset limpio para análisis/EDA.\n",
        "\n",
        "Nota: Cada celda de código es corta y va precedida de una explicación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparación e importaciones\n",
        "\n",
        "Usaremos `pandas` (`pd`), `numpy` (`np`) y `pathlib.Path` para rutas. En la celda de abajo:\n",
        "- `Path(...).mkdir(parents=True, exist_ok=True)` crea la carpeta de salida si no existe.\n",
        "- Mostramos versiones con `pd.__version__`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versiones:\n",
            "pandas= 2.3.3\n",
            "Salida: data/clean\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Versiones:\")\n",
        "print(\"pandas=\", pd.__version__)\n",
        "\n",
        "OUT_DIR = Path(\"data/clean\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Salida:\", OUT_DIR.as_posix())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creamos datos \"sucios\" (ventas y clientes)\n",
        "\n",
        "Usamos `pd.DataFrame({...})` para construir ejemplos con errores reales:\n",
        "- Fechas con formatos mixtos, montos como texto con símbolos y espacios.\n",
        "- Espacios y mayúsculas/minúsculas inconsistentes en texto.\n",
        "- Duplicados en `venta_id` y `cliente_id`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ventas sucias:\n",
            "   venta_id  cliente_id             fecha   monto categoria     canal\n",
            "0         1       101.0        2024-01-01    $100        A        Web\n",
            "1         2       102.0        2024/01/02  200.5          b   tienda \n",
            "2         2       102.0        02-01-2024     dos         B    Tienda\n",
            "3         3       103.0        2024-13-01    None      None       WEB\n",
            "4         4         NaN              None      -5         A         ?\n",
            "5         5       104.0  2024-01-05 10:00     300         b       web\n",
            "\n",
            "Clientes sucios:\n",
            "   cliente_id nombre  pais\n",
            "0         101   Ana    mx \n",
            "1         102   luis    MX\n",
            "2         102   LUIS    mx\n",
            "3         105   Mara    US\n"
          ]
        }
      ],
      "source": [
        "ventas_raw = pd.DataFrame({\n",
        "    \"venta_id\": [1, 2, 2, 3, 4, 5],\n",
        "    \"cliente_id\": [101, 102, 102, 103, None, 104],\n",
        "    \"fecha\": [\n",
        "        \"2024-01-01\", \"2024/01/02\", \"02-01-2024\", \"2024-13-01\", None, \"2024-01-05 10:00\"\n",
        "    ],\n",
        "    \"monto\": [\"$100\", \"200.5 \", \"dos\", None, \"-5\", \" 300\"],\n",
        "    \"categoria\": [\" A \", \"b\", \"B\", None, \"A\", \"b\"],\n",
        "    \"canal\": [\"Web\", \" tienda \", \"Tienda\", \"WEB\", \"?\", \"web\"],\n",
        "})\n",
        "\n",
        "clientes_raw = pd.DataFrame({\n",
        "    \"cliente_id\": [101, 102, 102, 105],\n",
        "    \"nombre\": [\" Ana \", \"luis\", \"LUIS\", \"Mara\"],\n",
        "    \"pais\": [\" mx \", \"MX\", \"mx\", \"US\"],\n",
        "})\n",
        "\n",
        "print(\"Ventas sucias:\")\n",
        "print(ventas_raw)\n",
        "print(\"\\nClientes sucios:\")\n",
        "print(clientes_raw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vistazo rápido (head, info)\n",
        "\n",
        "Usamos `DataFrame.head()` para una muestra rápida y `DataFrame.info()` para ver tipos y nulos por columna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ventas_raw.head():\n",
            "   venta_id  cliente_id       fecha   monto categoria     canal\n",
            "0         1       101.0  2024-01-01    $100        A        Web\n",
            "1         2       102.0  2024/01/02  200.5          b   tienda \n",
            "2         2       102.0  02-01-2024     dos         B    Tienda\n",
            "3         3       103.0  2024-13-01    None      None       WEB\n",
            "4         4         NaN        None      -5         A         ?\n",
            "\n",
            "clientes_raw.head():\n",
            "   cliente_id nombre  pais\n",
            "0         101   Ana    mx \n",
            "1         102   luis    MX\n",
            "2         102   LUIS    mx\n",
            "3         105   Mara    US\n",
            "\n",
            "Info ventas_raw:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 6 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   venta_id    6 non-null      int64  \n",
            " 1   cliente_id  5 non-null      float64\n",
            " 2   fecha       5 non-null      object \n",
            " 3   monto       5 non-null      object \n",
            " 4   categoria   5 non-null      object \n",
            " 5   canal       6 non-null      object \n",
            "dtypes: float64(1), int64(1), object(4)\n",
            "memory usage: 420.0+ bytes\n",
            "None\n",
            "\n",
            "Info clientes_raw:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   cliente_id  4 non-null      int64 \n",
            " 1   nombre      4 non-null      object\n",
            " 2   pais        4 non-null      object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 228.0+ bytes\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"ventas_raw.head():\")\n",
        "print(ventas_raw.head())\n",
        "print(\"\\nclientes_raw.head():\")\n",
        "print(clientes_raw.head())\n",
        "print(\"\\nInfo ventas_raw:\")\n",
        "print(ventas_raw.info())\n",
        "print(\"\\nInfo clientes_raw:\")\n",
        "print(clientes_raw.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalización de texto\n",
        "\n",
        "Funciones usadas en la celda siguiente:\n",
        "- `Series.astype(str)` para garantizar tipo string.\n",
        "- `Series.str.strip()` para quitar espacios al inicio/fin.\n",
        "- `Series.str.title()`, `Series.str.upper()`, `Series.str.lower()` para homogenizar casing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto normalizado (clientes):\n",
            "   cliente_id nombre pais\n",
            "0         101    Ana   MX\n",
            "1         102   Luis   MX\n",
            "2         102   Luis   MX\n",
            "3         105   Mara   US\n",
            "\n",
            "Texto normalizado (ventas):\n",
            "   venta_id  cliente_id       fecha   monto categoria   canal\n",
            "0         1       101.0  2024-01-01    $100         a     web\n",
            "1         2       102.0  2024/01/02  200.5          b  tienda\n",
            "2         2       102.0  02-01-2024     dos         b  tienda\n",
            "3         3       103.0  2024-13-01    None      none     web\n",
            "4         4         NaN        None      -5         a       ?\n"
          ]
        }
      ],
      "source": [
        "ventas = ventas_raw.copy()\n",
        "clientes = clientes_raw.copy()\n",
        "\n",
        "clientes[\"nombre\"] = clientes[\"nombre\"].astype(str).str.strip().str.title()\n",
        "clientes[\"pais\"] = clientes[\"pais\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "ventas[\"categoria\"] = ventas[\"categoria\"].astype(str).str.strip().str.lower()\n",
        "ventas[\"canal\"] = ventas[\"canal\"].astype(str).str.strip().str.lower()\n",
        "\n",
        "print(\"Texto normalizado (clientes):\\n\", clientes.head(), sep=\"\")\n",
        "print(\"\\nTexto normalizado (ventas):\\n\", ventas.head(), sep=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversión de tipos (numérico y fecha)\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.str.replace()` para remover símbolos y espacios.\n",
        "- `pd.to_numeric(..., errors='coerce')` para convertir `monto` a número.\n",
        "- `pd.to_datetime(..., errors='coerce', utc=True)` para parsear y normalizar `fecha` a UTC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Montos y fechas convertidos:\n",
            "   monto                     fecha\n",
            "0  100.0 2024-01-01 00:00:00+00:00\n",
            "1  200.5                       NaT\n",
            "2    NaN                       NaT\n",
            "3    NaN                       NaT\n",
            "4   -5.0                       NaT\n",
            "5  300.0                       NaT\n"
          ]
        }
      ],
      "source": [
        "ventas[\"monto\"] = ventas[\"monto\"].astype(str).str.replace(\"$\", \"\", regex=False).str.strip()\n",
        "ventas[\"monto\"] = pd.to_numeric(ventas[\"monto\"], errors=\"coerce\")\n",
        "ventas[\"fecha\"] = pd.to_datetime(ventas[\"fecha\"], errors=\"coerce\", utc=True)\n",
        "\n",
        "print(\"Montos y fechas convertidos:\")\n",
        "print(ventas[[\"monto\", \"fecha\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nulos: diagnóstico y tratamiento\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `DataFrame.isna().sum()` para conteo de nulos.\n",
        "- Asignación condicional con `DataFrame.loc[cond, col] = ...`.\n",
        "- `Series.replace({...})` para marcar valores especiales como `NaN`.\n",
        "- `Series.fillna(...)` para imputar valores faltantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conteo de nulos antes:\n",
            "venta_id      0\n",
            "cliente_id    1\n",
            "fecha         5\n",
            "monto         2\n",
            "categoria     0\n",
            "canal         0\n",
            "dtype: int64\n",
            "\n",
            "Imputamos 'canal' faltante con 'web' (ejemplo simple):\n",
            "\n",
            "Conteo de nulos después:\n",
            "venta_id      0\n",
            "cliente_id    1\n",
            "fecha         5\n",
            "monto         3\n",
            "categoria     0\n",
            "canal         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Conteo de nulos antes:\")\n",
        "print(ventas.isna().sum())\n",
        "\n",
        "ventas.loc[ventas[\"monto\"] < 0, \"monto\"] = np.nan\n",
        "ventas[\"canal\"] = ventas[\"canal\"].replace({\"?\": np.nan})\n",
        "\n",
        "print(\"\\nImputamos 'canal' faltante con 'web' (ejemplo simple):\")\n",
        "ventas[\"canal\"] = ventas[\"canal\"].fillna(\"web\")\n",
        "\n",
        "print(\"\\nConteo de nulos después:\")\n",
        "print(ventas.isna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reemplazos y estandarización\n",
        "\n",
        "Usamos `Series.replace({...})` para mapear valores a categorías estándar y para tratar variantes (`\"a\"→\"A\"`, `\"b\"→\"B\"`). Si hubiera patrones, puede usarse `regex=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     categoria   canal\n",
            "0            A     web\n",
            "1            B  tienda\n",
            "2            B  tienda\n",
            "3  desconocido     web\n",
            "4            A     web\n"
          ]
        }
      ],
      "source": [
        "ventas[\"categoria\"] = ventas[\"categoria\"].replace({np.nan: \"desconocido\"})\n",
        "ventas[\"categoria\"] = ventas[\"categoria\"].replace({\"a\": \"A\", \"b\": \"B\", \"none\": \"desconocido\"})\n",
        "\n",
        "print(ventas[[\"categoria\", \"canal\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Catálogo y homologación por join\n",
        "\n",
        "En la celda de abajo:\n",
        "- Construimos `cat_map` con `pd.DataFrame`.\n",
        "- Homologamos con `pd.merge(..., how='left', indicator=True)` para ver `_merge` (`left_only/right_only/both`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado de join de categorías (primeras filas):\n",
            "   venta_id    categoria categoria_final _merge\n",
            "0         1            A               A   both\n",
            "1         2            B               B   both\n",
            "2         2            B               B   both\n",
            "3         3  desconocido     DESCONOCIDO   both\n",
            "4         4            A               A   both\n",
            "\n",
            "Conteo por _merge:\n",
            "_merge\n",
            "both          6\n",
            "left_only     0\n",
            "right_only    0\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "cat_map = pd.DataFrame({\n",
        "    \"categoria\": [\"A\", \"B\", \"desconocido\"],\n",
        "    \"categoria_final\": [\"A\", \"B\", \"DESCONOCIDO\"],\n",
        "})\n",
        "\n",
        "merged_cats = pd.merge(\n",
        "    ventas[[\"venta_id\", \"categoria\"]],\n",
        "    cat_map,\n",
        "    on=\"categoria\",\n",
        "    how=\"left\",\n",
        "    indicator=True,\n",
        ")\n",
        "print(\"Resultado de join de categorías (primeras filas):\")\n",
        "print(merged_cats.head())\n",
        "print(\"\\nConteo por _merge:\")\n",
        "print(merged_cats[\"_merge\"].value_counts())\n",
        "\n",
        "ventas = ventas.merge(cat_map, on=\"categoria\", how=\"left\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriquecimiento con clientes (left join) y auditoría\n",
        "\n",
        "Usamos `pd.merge(ventas, clientes, on='cliente_id', how='left', indicator=True)` para enriquecer y auditar con `_merge` cuántas filas no hicieron match (`left_only`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado de enriquecimiento (primeras filas):\n",
            "   venta_id  cliente_id                     fecha  monto categoria   canal  \\\n",
            "0         1       101.0 2024-01-01 00:00:00+00:00  100.0         A     web   \n",
            "1         2       102.0                       NaT  200.5         B  tienda   \n",
            "2         2       102.0                       NaT  200.5         B  tienda   \n",
            "3         2       102.0                       NaT    NaN         B  tienda   \n",
            "4         2       102.0                       NaT    NaN         B  tienda   \n",
            "\n",
            "  categoria_final nombre pais _merge  \n",
            "0               A    Ana   MX   both  \n",
            "1               B   Luis   MX   both  \n",
            "2               B   Luis   MX   both  \n",
            "3               B   Luis   MX   both  \n",
            "4               B   Luis   MX   both  \n",
            "\n",
            "Conteo por _merge (espera left_only si cliente_id faltó o no existía en clientes):\n",
            "_merge\n",
            "both          5\n",
            "left_only     3\n",
            "right_only    0\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "ventas_enr = pd.merge(\n",
        "    ventas,\n",
        "    clientes,\n",
        "    on=\"cliente_id\",\n",
        "    how=\"left\",\n",
        "    indicator=True,\n",
        ")\n",
        "print(\"Resultado de enriquecimiento (primeras filas):\")\n",
        "print(ventas_enr.head())\n",
        "print(\"\\nConteo por _merge (espera left_only si cliente_id faltó o no existía en clientes):\")\n",
        "print(ventas_enr[\"_merge\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Duplicados y llaves\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.duplicated()` para detectar duplicados.\n",
        "- `DataFrame.drop_duplicates(subset=[...], keep='first')` para deduplicar por llave.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicados en ventas por venta_id:\n",
            "venta_id\n",
            "False    5\n",
            "True     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Ventas tras drop_duplicates:\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(\"Duplicados en ventas por venta_id:\")\n",
        "print(ventas_enr[\"venta_id\"].duplicated().value_counts())\n",
        "\n",
        "ventas_enr = ventas_enr.drop_duplicates(subset=[\"venta_id\"], keep=\"first\")\n",
        "print(\"\\nVentas tras drop_duplicates:\")\n",
        "print(len(ventas_enr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validaciones y reglas de negocio\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.clip(lower=0)` para cortar valores negativos.\n",
        "- `DataFrame.dropna(subset=[...])` para exigir presencia de campos críticos (p. ej., `fecha`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros con fecha válida: 1\n",
            "Ventas válidas (sin NaT en fecha): 1\n"
          ]
        }
      ],
      "source": [
        "ventas_enr[\"monto\"] = ventas_enr[\"monto\"].clip(lower=0)\n",
        "registros_con_fecha = ventas_enr[\"fecha\"].notna().sum()\n",
        "print(\"Registros con fecha válida:\", registros_con_fecha)\n",
        "\n",
        "# Si consideras obligatorio 'fecha' para toda venta, filtra:\n",
        "ventas_validas = ventas_enr.dropna(subset=[\"fecha\"])  # decisión explícita\n",
        "print(\"Ventas válidas (sin NaT en fecha):\", len(ventas_validas))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outliers (percentiles y `clip`)\n",
        "\n",
        "Herramientas sugeridas para la celda siguiente (si decides aplicarlo):\n",
        "- `Series.quantile([0.01, 0.99])` para estimar umbrales p1–p99.\n",
        "- `Series.clip(lower=..., upper=...)` para recortar extremos de `monto`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deduplicación de clientes y `validate`\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `DataFrame.drop_duplicates(subset=[...])` para deduplicar catálogo de clientes.\n",
        "- `pd.merge(..., validate='m:1')` para asegurar relación muchas-ventas-a-un-cliente sin duplicaciones inesperadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clientes antes/after dedup:\n",
            "4 3\n",
            "\n",
            "Enriquecimiento validado m:1 (primeras filas):\n",
            "   venta_id  cliente_id                     fecha  monto    categoria   canal  \\\n",
            "0         1       101.0 2024-01-01 00:00:00+00:00  100.0            A     web   \n",
            "1         2       102.0                       NaT  200.5            B  tienda   \n",
            "2         2       102.0                       NaT    NaN            B  tienda   \n",
            "3         3       103.0                       NaT    NaN  desconocido     web   \n",
            "4         4         NaN                       NaT    NaN            A     web   \n",
            "\n",
            "  categoria_final nombre pais     _merge  \n",
            "0               A    Ana   MX       both  \n",
            "1               B   Luis   MX       both  \n",
            "2               B   Luis   MX       both  \n",
            "3     DESCONOCIDO    NaN  NaN  left_only  \n",
            "4               A    NaN  NaN  left_only  \n",
            "\n",
            "_merge counts:\n",
            "_merge\n",
            "left_only     3\n",
            "both          3\n",
            "right_only    0\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "clientes_dedup = clientes.drop_duplicates(subset=[\"cliente_id\"], keep=\"first\")\n",
        "print(\"Clientes antes/after dedup:\")\n",
        "print(len(clientes), len(clientes_dedup))\n",
        "\n",
        "ventas_enr_v = pd.merge(\n",
        "    ventas,\n",
        "    clientes_dedup,\n",
        "    on=\"cliente_id\",\n",
        "    how=\"left\",\n",
        "    validate=\"m:1\",\n",
        "    indicator=True,\n",
        ")\n",
        "print(\"\\nEnriquecimiento validado m:1 (primeras filas):\")\n",
        "print(ventas_enr_v.head())\n",
        "print(\"\\n_merge counts:\")\n",
        "print(ventas_enr_v[\"_merge\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen de calidad y validaciones rápidas\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.is_unique` para validar unicidad de `venta_id`.\n",
        "- `DataFrame.isna().sum()` para conteo de nulos en campos clave.\n",
        "- `Series.value_counts(dropna=False)` para distribuciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unicidad de venta_id (espera True): False\n",
            "\n",
            "Nulos en campos clave:\n",
            "venta_id      0\n",
            "cliente_id    1\n",
            "fecha         5\n",
            "monto         3\n",
            "dtype: int64\n",
            "\n",
            "Distribución de canal:\n",
            "canal\n",
            "web       4\n",
            "tienda    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución de categoria_final:\n",
            "categoria_final\n",
            "B              3\n",
            "A              2\n",
            "DESCONOCIDO    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Unicidad de venta_id (espera True):\", ventas_enr_v[\"venta_id\"].is_unique)\n",
        "print(\"\\nNulos en campos clave:\")\n",
        "print(ventas_enr_v[[\"venta_id\", \"cliente_id\", \"fecha\", \"monto\"]].isna().sum())\n",
        "\n",
        "print(\"\\nDistribución de canal:\")\n",
        "print(ventas_enr_v[\"canal\"].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\nDistribución de categoria_final:\")\n",
        "print(ventas_enr_v[\"categoria_final\"].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardado de datos limpios\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `DataFrame.sort_values(...)` para ordenar al exportar.\n",
        "- `DataFrame.to_csv(...)` y `DataFrame.to_parquet(...)` para persistencia eficiente.\n",
        "- `Path` para construir rutas de salida.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Guardado CSV, Parquet no disponible: data/clean/dataset_limpio.csv | Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
            "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
            "Trying to import the above resulted in these errors:\n",
            " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
            " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\n",
            "\n",
            "Muestra final:\n",
            "   venta_id  cliente_id                     fecha  monto categoria_final  \\\n",
            "0         1       101.0 2024-01-01 00:00:00+00:00  100.0               A   \n",
            "1         2       102.0                       NaT  200.5               B   \n",
            "2         2       102.0                       NaT    NaN               B   \n",
            "3         3       103.0                       NaT    NaN     DESCONOCIDO   \n",
            "5         5       104.0                       NaT  300.0               B   \n",
            "\n",
            "    canal nombre pais  \n",
            "0     web    Ana   MX  \n",
            "1  tienda   Luis   MX  \n",
            "2  tienda   Luis   MX  \n",
            "3     web    NaN  NaN  \n",
            "5     web    NaN  NaN  \n"
          ]
        }
      ],
      "source": [
        "cols_finales = [\n",
        "    \"venta_id\", \"cliente_id\", \"fecha\", \"monto\",\n",
        "    \"categoria_final\", \"canal\", \"nombre\", \"pais\"\n",
        "]\n",
        "limpio_v2 = ventas_enr_v[cols_finales].sort_values([\"cliente_id\", \"fecha\", \"venta_id\"], na_position=\"last\")\n",
        "\n",
        "csv_path = OUT_DIR / \"dataset_limpio.csv\"\n",
        "parquet_path = OUT_DIR / \"dataset_limpio_v2.parquet\"\n",
        "\n",
        "limpio_v2.to_csv(csv_path, index=False)\n",
        "try:\n",
        "    limpio_v2.to_parquet(parquet_path, index=False)\n",
        "    print(\"Guardado CSV y Parquet:\", csv_path.as_posix(), parquet_path.as_posix())\n",
        "except Exception as e:\n",
        "    print(\"Guardado CSV, Parquet no disponible:\", csv_path.as_posix(), \"|\", e)\n",
        "\n",
        "print(\"\\nMuestra final:\")\n",
        "print(limpio_v2.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checklist final\n",
        "\n",
        "- Tipos normalizados (`monto` numérico, `fecha` UTC, textos homogéneos).\n",
        "- Nulos tratados: canales imputados, montos negativos a `NaN`.\n",
        "- Catálogo aplicado a `categoria` → `categoria_final`.\n",
        "- Enriquecimiento con `clientes` validado `m:1`.\n",
        "- Duplicados removidos en `venta_id` y catálogo deduplicado.\n",
        "- Datos guardados en `professor/pandas_v2/data/clean/` como `dataset_limpio_v2.*`.\n",
        "\n",
        "Siguiente: usa el notebook 05 para EDA con `groupby`, `pivot_table` y `MultiIndex`.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
