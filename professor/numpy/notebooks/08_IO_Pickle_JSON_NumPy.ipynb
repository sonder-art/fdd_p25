{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/sonder-art/fdd_p25/blob/main/professor/numpy/notebooks/08_IO_Pickle_JSON_NumPy.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08 — Entrada/Salida: Pickle, JSON y NumPy (profundizado)\n",
        "\n",
        "Objetivo: entender a fondo cómo guardar y cargar datos con Python y NumPy, cuándo usar cada formato y sus implicaciones de legibilidad, tamaño, portabilidad y seguridad.\n",
        "\n",
        "¿Qué veremos?\n",
        "- Pickle: qué es, cómo funciona (a alto nivel), protocolos, riesgos de seguridad, cuándo usarlo.\n",
        "- JSON: formato legible por humanos; `indent`, `ensure_ascii`, `sort_keys`, tamaños y limitaciones.\n",
        "- NumPy: `np.save`, `np.load`, `np.savez`, `np.savez_compressed` para arreglos eficientes.\n",
        "- Serialización de objetos NumPy en JSON: por qué falla directo y cómo hacerlo bien.\n",
        "- Demostraciones desde la terminal con `!ls`, `!file`, `!head`, `!tail` para inspección.\n",
        "\n",
        "Regla rápida:\n",
        "- ¿Necesitas legibilidad humana y compatibilidad? JSON.\n",
        "- ¿Necesitas arreglos NumPy grandes y eficientes? Formatos NumPy.\n",
        "- ¿Necesitas serializar objetos Python arbitrarios (no seguros)? Pickle, con cuidado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (ndarray + pickle)\n",
        "\n",
        "- Crea un `ndarray` y lo guarda en `array.pkl` con `pickle`.\n",
        "- Modifica el arreglo original para demostrar que el archivo conserva el estado anterior.\n",
        "- Carga el pickle y verifica que se recupera el arreglo guardado.\n",
        "- Recalca: el pickle es binario y no legible por humanos, pero guarda estructura/dtype/shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5]), array([-1,  2,  3,  4,  5]))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np, pickle, json, os, sys\n",
        "\n",
        "# Pickle: qué es y cómo funciona (alto nivel)\n",
        "# - Serializa objetos Python a un flujo binario (no legible por humanos).\n",
        "# - Usa \"protocolos\" (versiones); por defecto, protocolo más alto disponible.\n",
        "# - Riesgo: cargar (`pickle.load`) puede ejecutar código arbitrario. No cargues archivos no confiables.\n",
        "\n",
        "# Guardar y cargar con pickle (ndarray)\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "with open(\"array.pkl\", \"wb\") as f:\n",
        "    pickle.dump(arr, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "arr[0] = -1\n",
        "with open(\"array.pkl\", \"rb\") as f:\n",
        "    loaded = pickle.load(f)\n",
        "(\n",
        "loaded,\n",
        "arr\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (dict + pickle)\n",
        "\n",
        "- Serializa un diccionario con `pickle` usando el protocolo más alto.\n",
        "- El archivo resultante es binario y no legible por humanos.\n",
        "- Se decodifica con `pickle.load` para reconstruir el objeto original.\n",
        "- Precaución: no cargues pickles de fuentes no confiables (riesgo de ejecución de código).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'John Doe', 'age': 32, 'email': 'johndoe@example.com'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dict + pickle (binario no legible)\n",
        "data = {\"name\": \"John Doe\", \"age\": 32, \"email\": \"johndoe@example.com\"}\n",
        "with open(\"data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open(\"data.pkl\", \"rb\") as f:\n",
        "    data_loaded = pickle.load(f)\n",
        "data_loaded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (JSON legible)\n",
        "\n",
        "- Escribe el `dict` en JSON con `indent=2` (más legible), `sort_keys=True` (orden de claves determinista) y `ensure_ascii=False` (caracteres tal cual).\n",
        "- Lee de vuelta para comprobar la sintaxis y la decodificación.\n",
        "- Recuerda: más legibilidad → mayor tamaño físico del archivo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JSON legible (humano): indent, sort_keys, UTF-8\n",
        "with open(\"data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=2, ensure_ascii=False, sort_keys=True)\n",
        "with open(\"data.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (NumPy + JSON)\n",
        "\n",
        "- Muestra que `json.dumps(np.array(...))` falla porque `ndarray` no es JSON serializable.\n",
        "- Define una función `default` que convierte `ndarray` a listas y `np.generic` a escalares de Python.\n",
        "- Guarda un `ndarray` en JSON usando `default` y lo lee de vuelta.\n",
        "- Nota: este enfoque pierde `dtype`/`shape` (se recuperan como lista y tipos Python). Más abajo hay un round‑trip con metadatos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error esperado: Object of type ndarray is not JSON serializable\n"
          ]
        }
      ],
      "source": [
        "# JSON + NumPy: falla directo, usar default para serializar\n",
        "# Edge case: ndarray/np.number no son JSON serializables por defecto\n",
        "try:\n",
        "    json.dumps(np.array([1, 2, 3]))\n",
        "except TypeError as e:\n",
        "    print(\"Error esperado:\", e)\n",
        "\n",
        "# Encoder: convertir ndarray -> list, np.number -> Python scalar\n",
        "\n",
        "def json_serializable(o):\n",
        "    if isinstance(o, np.ndarray):\n",
        "        return o.tolist()\n",
        "    if isinstance(o, np.generic):  # cubre np.number, np.int64, etc.\n",
        "        return o.item()\n",
        "    raise TypeError(f\"No serializable: {type(o)}\")\n",
        "\n",
        "arr2 = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int64)\n",
        "with open(\"ndarray_json.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(arr2, f, default=json_serializable)\n",
        "with open(\"ndarray_json.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (UTF‑8 y caracteres)\n",
        "\n",
        "- Escribe una cadena con caracteres no ASCII (Ñ, acentos y kanji) en JSON.\n",
        "- Usa `ensure_ascii=False` para mantener los caracteres tal cual (sin escapes `\\uXXXX`).\n",
        "- Lee de vuelta para verificar que la codificación UTF‑8 funciona correctamente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ñ á é 漢字'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# UTF-8 y caracteres especiales\n",
        "with open(\"string.json\", \"w\") as f:\n",
        "    json.dump(\"Ñ á é 漢字\", f, ensure_ascii=True)\n",
        "with open(\"string.json\", \"r\") as f:\n",
        "    a = json.load(f)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pickle en detalle: protocolos y seguridad\n",
        "\n",
        "- Formato binario específico de Python: no legible por humanos ni portable fuera de Python.\n",
        "- Protocolos: versiones de serialización (mayor protocolo = mejor rendimiento/compatibilidad con tipos nuevos). Usa `pickle.HIGHEST_PROTOCOL`.\n",
        "- Seguridad: `pickle.load` puede ejecutar código arbitrario. Solo carga archivos de fuentes confiables. Alternativas seguras: JSON (legible) o formatos NumPy.\n",
        "- Portabilidad: pickles viejos pueden fallar en versiones nuevas o con cambios de clases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (inspección con shell)\n",
        "\n",
        "- Lista archivos generados y tamaños (`!ls -lh`).\n",
        "- Muestra tipo de archivo detectado por el sistema (`!file`), evidenciando que Pickle es binario y JSON es texto.\n",
        "- Enseña por qué no tiene sentido usar `head` en binarios (bytes no legibles), y muestra `head` de un JSON como ejemplo de legibilidad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-rw-r-- 1 uumami uumami 167 Oct 23 20:19 array.pkl\n",
            "-rw-rw-r-- 1 uumami uumami  71 Oct 23 20:22 data.json\n",
            "-rw-rw-r-- 1 uumami uumami  72 Oct 23 20:20 data.pkl\n",
            "-rw-rw-r-- 1 uumami uumami  22 Oct 23 20:22 ndarray_json.json\n",
            "-rw-rw-r-- 1 uumami uumami  35 Oct 23 20:24 string.json\n",
            "array.pkl:         XENIX 8086 relocatable or 80286 small model\n",
            "data.pkl:          XENIX 8086 relocatable or 80286 small model\n",
            "data.json:         JSON data\n",
            "ndarray_json.json: JSON data\n",
            "string.json:       ASCII text, with no line terminators\n",
            "\n",
            "--- Print head del pkl directo: array.pkl:  ---\n",
            "�\u0005��\u0000\u0000\u0000\u0000\u0000\u0000\u0000�\u0013numpy._core.numeric��\u000b_frombuffer���(�(\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000��\u0005numpy��\u0005dtype����\u0002i8�����R�(K\u0003�\u0001<�NNNJ����J����K\u0000t�bK\u0005���\u0001C�t�R�.\n",
            "--- array.pkl: hexdump head (64 bytes) ---\n",
            "00000000  80 05 95 9c 00 00 00 00  00 00 00 8c 13 6e 75 6d  |.............num|\n",
            "00000010  70 79 2e 5f 63 6f 72 65  2e 6e 75 6d 65 72 69 63  |py._core.numeric|\n",
            "00000020  94 8c 0b 5f 66 72 6f 6d  62 75 66 66 65 72 94 93  |..._frombuffer..|\n",
            "00000030  94 28 96 28 00 00 00 00  00 00 00 01 00 00 00 00  |.(.(............|\n",
            "00000040\n",
            "\n",
            "--- array.pkl: hexdump tail (64 bytes) ---\n",
            "00000000  75 6d 70 79 94 8c 05 64  74 79 70 65 94 93 94 8c  |umpy...dtype....|\n",
            "00000010  02 69 38 94 89 88 87 94  52 94 28 4b 03 8c 01 3c  |.i8.....R.(K...<|\n",
            "00000020  94 4e 4e 4e 4a ff ff ff  ff 4a ff ff ff ff 4b 00  |.NNNJ....J....K.|\n",
            "00000030  74 94 62 4b 05 85 94 8c  01 43 94 74 94 52 94 2e  |t.bK.....C.t.R..|\n",
            "00000040\n",
            "\n",
            "--- array.pkl: strings (primeras 5 líneas) ---\n",
            "numpy._core.numeric\n",
            "_frombuffer\n",
            "numpy\n",
            "dtype\n",
            "NNNJ\n",
            "\n",
            "--- data.pkl: hexdump head (64 bytes) ---\n",
            "00000000  80 05 95 3d 00 00 00 00  00 00 00 7d 94 28 8c 04  |...=.......}.(..|\n",
            "00000010  6e 61 6d 65 94 8c 08 4a  6f 68 6e 20 44 6f 65 94  |name...John Doe.|\n",
            "00000020  8c 03 61 67 65 94 4b 20  8c 05 65 6d 61 69 6c 94  |..age.K ..email.|\n",
            "00000030  8c 13 6a 6f 68 6e 64 6f  65 40 65 78 61 6d 70 6c  |..johndoe@exampl|\n",
            "00000040\n",
            "\n",
            "--- data.pkl: hexdump tail (64 bytes) ---\n",
            "00000000  00 00 00 7d 94 28 8c 04  6e 61 6d 65 94 8c 08 4a  |...}.(..name...J|\n",
            "00000010  6f 68 6e 20 44 6f 65 94  8c 03 61 67 65 94 4b 20  |ohn Doe...age.K |\n",
            "00000020  8c 05 65 6d 61 69 6c 94  8c 13 6a 6f 68 6e 64 6f  |..email...johndo|\n",
            "00000030  65 40 65 78 61 6d 70 6c  65 2e 63 6f 6d 94 75 2e  |e@example.com.u.|\n",
            "00000040\n",
            "\n",
            "--- data.pkl: strings (primeras 5 líneas) ---\n",
            "name\n",
            "John Doe\n",
            "email\n",
            "johndoe@example.com\n",
            "\n",
            "--- data.json (head) ---\n",
            "{\n",
            "  \"age\": 32,\n",
            "  \"email\": \"johndoe@example.com\",\n",
            "  \"name\": \"John Doe\"\n",
            "}\n",
            "--- data.json (tail) ---\n",
            "{\n",
            "  \"age\": 32,\n",
            "  \"email\": \"johndoe@example.com\",\n",
            "  \"name\": \"John Doe\"\n",
            "}\n",
            "--- ndarray_json.json (head) ---\n",
            "[[1, 2, 3], [4, 5, 6]]\n",
            "--- ndarray_json.json (tail) ---\n",
            "[[1, 2, 3], [4, 5, 6]]\n",
            "--- string.json (head) ---\n",
            "\"\\u00d1 \\u00e1 \\u00e9 \\u6f22\\u5b57\"\n",
            "--- string.json (tail) ---\n",
            "\"\\u00d1 \\u00e1 \\u00e9 \\u6f22\\u5b57\""
          ]
        }
      ],
      "source": [
        "\n",
        "# Inspección extendida con shell: tamaños, tipos, head/tail y strings\n",
        "!ls -lh array.pkl data.pkl data.json ndarray_json.json string.json\n",
        "!file array.pkl data.pkl data.json ndarray_json.json string.json\n",
        "\n",
        "print(\"\\n--- Print head del pkl directo: array.pkl:  ---\")\n",
        "!head array.pkl\n",
        "\n",
        "# Binarios: usar hexdump para ver bytes (no legible por humanos)\n",
        "print(\"\\n--- array.pkl: hexdump head (64 bytes) ---\")\n",
        "!hexdump -C -n 64 array.pkl | head -n 10\n",
        "print(\"\\n--- array.pkl: hexdump tail (64 bytes) ---\")\n",
        "!tail -c 64 array.pkl | hexdump -C\n",
        "print(\"\\n--- array.pkl: strings (primeras 5 líneas) ---\")\n",
        "!bash -lc 'command -v strings >/dev/null 2>&1 && strings -n 4 array.pkl | head -n 5 || echo \"strings no disponible\"'\n",
        "\n",
        "print(\"\\n--- data.pkl: hexdump head (64 bytes) ---\")\n",
        "!hexdump -C -n 64 data.pkl | head -n 10\n",
        "print(\"\\n--- data.pkl: hexdump tail (64 bytes) ---\")\n",
        "!tail -c 64 data.pkl | hexdump -C\n",
        "print(\"\\n--- data.pkl: strings (primeras 5 líneas) ---\")\n",
        "!bash -lc 'command -v strings >/dev/null 2>&1 && strings -n 4 data.pkl | head -n 5 || echo \"strings no disponible\"'\n",
        "\n",
        "# JSON (texto): head/tail muestran contenido legible\n",
        "print(\"\\n--- data.json (head) ---\")\n",
        "!head -n 5 data.json\n",
        "print(\"\\n--- data.json (tail) ---\")\n",
        "!tail -n 5 data.json\n",
        "\n",
        "print(\"\\n--- ndarray_json.json (head) ---\")\n",
        "!head -n 5 ndarray_json.json\n",
        "print(\"\\n--- ndarray_json.json (tail) ---\")\n",
        "!tail -n 5 ndarray_json.json\n",
        "\n",
        "print(\"\\n--- string.json (head) ---\")\n",
        "!head -n 5 string.json\n",
        "print(\"\\n--- string.json (tail) ---\")\n",
        "!tail -n 5 string.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## JSON en detalle: legibilidad y tamaños\n",
        "\n",
        "- Legible por humanos y ampliamente interoperable.\n",
        "- `indent` mejora legibilidad; `sort_keys` hace determinista el orden de claves.\n",
        "- `ensure_ascii=False` preserva caracteres no ASCII (útil en español y otros idiomas).\n",
        "- Tamaño: añadir `indent` y espacios aumenta el tamaño del archivo; úsalos cuando la legibilidad importe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-rw-r-- 1 uumami uumami  49 Oct 23 20:27 compact.json\n",
            "-rw-rw-r-- 1 uumami uumami 115 Oct 23 20:27 pretty.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 49 compact.json\n",
            "115 pretty.json\n",
            "164 total\n"
          ]
        }
      ],
      "source": [
        "# Comparar tamaños: JSON compacto vs legible\n",
        "small = {\"z\": 1, \"á\": \"hola\", \"lista\": list(range(10))}\n",
        "with open(\"compact.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(small, f, ensure_ascii=False, separators=(\",\", \":\"))\n",
        "with open(\"pretty.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(small, f, ensure_ascii=False, indent=2, sort_keys=True)\n",
        "!ls -lh compact.json pretty.json\n",
        "!wc -c compact.json pretty.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"lista\": [\n",
            "    0,\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5,\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    9\n",
            "  ],\n",
            "  \"z\": 1,\n",
            "  \"á\": \"hola\"\n",
            "}"
          ]
        }
      ],
      "source": [
        "!cat pretty.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Round‑trip JSON para `ndarray`: preservar `dtype` y `shape`\n",
        "\n",
        "Guardar como lista pierde la información de `dtype` y `shape`. Podemos incluir metadatos y reconstruir con `object_hook`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (Round‑trip JSON para `ndarray` con metadatos)\n",
        "\n",
        "Esta celda demuestra cómo guardar y recuperar arreglos de NumPy en JSON sin perder `dtype` ni `shape`, algo que se pierde si solo convertimos a listas.\n",
        "\n",
        "- Se define `NumpyEncoder`, un `JSONEncoder` personalizado que, cuando ve un `np.ndarray`, lo convierte a un `dict` con:\n",
        "  - `__ndarray__`: marca para reconocer que este `dict` representa un arreglo.\n",
        "  - `dtype`: el tipo (como string), por ejemplo `\"float32\"`.\n",
        "  - `shape`: la forma, por ejemplo `(3, 4)`.\n",
        "  - `data`: los datos como lista anidada (JSON no admite binarios ni `ndarray`).\n",
        "  También convierte `np.generic` (p. ej. `np.float32(1.0)`) a escalares de Python con `.item()`.\n",
        "\n",
        "- Se define `numpy_object_hook`, una función que `json.load` invoca para cada `dict` leído. Si encuentra la marca `__ndarray__`, reconstruye el arreglo con `np.array(..., dtype=...)` y lo re‑da forma con `reshape(shape)`.\n",
        "\n",
        "- Se crea `orig` con un `ndarray` y metadatos; se guarda con `json.dump(..., cls=NumpyEncoder, ...)` y se carga con `json.load(..., object_hook=numpy_object_hook)`.\n",
        "\n",
        "- Aserciones: comprueban que lo cargado es `np.ndarray`, que conserva `dtype` y `shape`, y que los valores coinciden con `np.allclose`.\n",
        "\n",
        "Notas prácticas:\n",
        "- Este método es portable y legible (JSON), pero los archivos pueden ser grandes y lentos para arreglos muy grandes.\n",
        "- Es “permisisvo”/seguro comparado con Pickle (no ejecuta código), a costa de más tamaño/CPU.\n",
        "- Para datos numéricos grandes, prefiere `np.save/np.load` o `np.savez(_compressed)`; usa este esquema JSON cuando necesites interoperabilidad y legibilidad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, o):\n",
        "        if isinstance(o, np.ndarray):\n",
        "            return {\n",
        "                \"__ndarray__\": True,\n",
        "                \"dtype\": str(o.dtype),\n",
        "                \"shape\": o.shape,\n",
        "                \"data\": o.tolist(),\n",
        "            }\n",
        "        if isinstance(o, np.generic):\n",
        "            return o.item()\n",
        "        return super().default(o)\n",
        "\n",
        "def numpy_object_hook(d):\n",
        "    if d.get(\"__ndarray__\"):\n",
        "        arr = np.array(d[\"data\"], dtype=np.dtype(d[\"dtype\"]))\n",
        "        return arr.reshape(d[\"shape\"])\n",
        "    return d\n",
        "\n",
        "orig = {\n",
        "    \"mat\": np.arange(12, dtype=np.float32).reshape(3, 4),\n",
        "    \"meta\": {\"name\": \"demo\"},\n",
        "}\n",
        "\n",
        "with open(\"arr_with_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(orig, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open(\"arr_with_meta.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    loaded = json.load(f, object_hook=numpy_object_hook)\n",
        "\n",
        "assert isinstance(loaded[\"mat\"], np.ndarray)\n",
        "assert loaded[\"mat\"].dtype == np.float32\n",
        "assert loaded[\"mat\"].shape == (3, 4)\n",
        "np.allclose(loaded[\"mat\"], orig[\"mat\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Edge cases en JSON: NaN/Inf y datetime\n",
        "\n",
        "- JSON estándar no tiene `NaN`/`Infinity`: Python permite `NaN` por defecto (`allow_nan=True`), pero otros parsers podrían fallar. Mejor mapear a `null` o strings.\n",
        "- Fechas: no hay tipo nativo; usa `ISO 8601` (string) y reconstruye con `object_hook`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON con NaN/Inf (no estándar): {\"nan\": NaN, \"inf\": Infinity}\n",
            "Seguro: {\"nan\": null, \"inf\": null}\n",
            "Datetime ISO: {\"timestamp\": \"2025-10-22T18:13:27.053653-06:00\"}\n"
          ]
        }
      ],
      "source": [
        "import math, datetime\n",
        "\n",
        "bad = {\"nan\": float(\"nan\"), \"inf\": float(\"inf\")}\n",
        "\n",
        "# Por defecto, Python permite NaN/Inf, pero no es JSON estándar\n",
        "s = json.dumps(bad)  # allow_nan=True por defecto\n",
        "print(\"JSON con NaN/Inf (no estándar):\", s)\n",
        "\n",
        "# Mapeo seguro: convertir a null\n",
        "safe = {k: None if isinstance(v, float) and (math.isnan(v) or math.isinf(v)) else v for k, v in bad.items()}\n",
        "print(\"Seguro:\", json.dumps(safe))\n",
        "\n",
        "# Datetime a ISO 8601\n",
        "now = datetime.datetime.now().astimezone()\n",
        "rec = {\"timestamp\": now.isoformat()}\n",
        "print(\"Datetime ISO:\", json.dumps(rec))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatos de NumPy: `npy` y `npz`\n",
        "\n",
        "Para arreglos grandes, usa formatos nativos de NumPy: rápidos y compactos.\n",
        "- `np.save`/`np.load` guardan/cargan un solo arreglo `.npy` (contiene dtype y shape).\n",
        "- `np.savez` guarda varios arreglos en `.npz` (zip sin compresión); `np.savez_compressed` aplica compresión (más pequeño, puede ser más lento al guardar/cargar).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-rw-r-- 1 uumami uumami 6.9M Oct 22 18:13 AB_comp.npz\n",
            "-rw-rw-r-- 1 uumami uumami 7.7M Oct 22 18:13 AB.npz\n",
            "-rw-rw-r-- 1 uumami uumami 3.9M Oct 22 18:13 A.npy\n",
            "True True True True True\n"
          ]
        }
      ],
      "source": [
        "A = np.random.rand(1000, 1000).astype(np.float32)\n",
        "B = np.random.rand(1000, 1000).astype(np.float32)\n",
        "np.save(\"A.npy\", A)\n",
        "np.savez(\"AB.npz\", A=A, B=B)\n",
        "np.savez_compressed(\"AB_comp.npz\", A=A, B=B)\n",
        "!ls -lh A.npy AB.npz AB_comp.npz\n",
        "\n",
        "# Carga y verificación\n",
        "A2 = np.load(\"A.npy\")\n",
        "with np.load(\"AB.npz\") as z:\n",
        "    A3, B3 = z[\"A\"], z[\"B\"]\n",
        "with np.load(\"AB_comp.npz\") as zc:\n",
        "    A4, B4 = zc[\"A\"], zc[\"B\"]\n",
        "\n",
        "print(np.allclose(A, A2), np.allclose(A, A3), np.allclose(B, B3), np.allclose(A, A4), np.allclose(B, B4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qué hace esta celda (inspección de formatos NumPy)\n",
        "\n",
        "- Genera arreglos `.npy` y archivos `.npz` (con y sin compresión) y muestra sus tamaños.\n",
        "- Carga de vuelta para verificar que los datos coinciden.\n",
        "- Demuestra que `.npy`/`.npz` no son legibles por humanos (binario/zip), a diferencia de JSON.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A.npy:       NumPy array, version 1.0, header length 118\n",
            "AB.npz:      Zip archive data, at least v2.0 to extract, compression method=store\n",
            "AB_comp.npz: Zip archive data, at least v2.0 to extract, compression method=deflate\n",
            "\n",
            "--- A.npy hexdump head (64 bytes) ---\n",
            "00000000  93 4e 55 4d 50 59 01 00  76 00 7b 27 64 65 73 63  |.NUMPY..v.{'desc|\n",
            "00000010  72 27 3a 20 27 3c 66 34  27 2c 20 27 66 6f 72 74  |r': '<f4', 'fort|\n",
            "00000020  72 61 6e 5f 6f 72 64 65  72 27 3a 20 46 61 6c 73  |ran_order': Fals|\n",
            "00000030  65 2c 20 27 73 68 61 70  65 27 3a 20 28 31 30 30  |e, 'shape': (100|\n",
            "00000040\n",
            "\n",
            "--- AB.npz listado ---\n",
            "Archive:  AB.npz\n",
            "  Length      Date    Time    Name\n",
            "---------  ---------- -----   ----\n",
            "  4000128  1980-01-01 00:00   A.npy\n",
            "  4000128  1980-01-01 00:00   B.npy\n",
            "---------                     -------\n",
            "  8000256                     2 files\n",
            "\n",
            "--- AB_comp.npz listado ---\n",
            "Archive:  AB_comp.npz\n",
            "  Length      Date    Time    Name\n",
            "---------  ---------- -----   ----\n",
            "  4000128  1980-01-01 00:00   A.npy\n",
            "  4000128  1980-01-01 00:00   B.npy\n",
            "---------                     -------\n",
            "  8000256                     2 files\n"
          ]
        }
      ],
      "source": [
        "# Inspección de NPY/NPZ: tipo y contenido parcial\n",
        "!file A.npy AB.npz AB_comp.npz\n",
        "\n",
        "print(\"\\n--- A.npy hexdump head (64 bytes) ---\")\n",
        "!hexdump -C -n 64 A.npy | head -n 10\n",
        "\n",
        "# NPZ es un ZIP: listar entradas\n",
        "print(\"\\n--- AB.npz listado ---\")\n",
        "!unzip -l AB.npz\n",
        "print(\"\\n--- AB_comp.npz listado ---\")\n",
        "!unzip -l AB_comp.npz\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
